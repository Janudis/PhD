{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.path.append(\"D:\\Python_Projects\\PhD_project\")\n",
    "# sys.path.insert(0, 'D:/Python_Projects/PhD_project')\n",
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from visualDet3D.visualDet3D.data.kitti.utils import write_result_to_file\n",
    "from visualDet3D.visualDet3D.utils.utils import LossLogger, cfg_from_file\n",
    "from visualDet3D.visualDet3D.networks.utils.registry import DETECTOR_DICT, DATASET_DICT, PIPELINE_DICT\n",
    "from visualDet3D.visualDet3D.networks.heads.anchors import Anchors\n",
    "from visualDet3D.visualDet3D.networks.lib.fast_utils.hill_climbing import post_opt\n",
    "from visualDet3D.visualDet3D.networks.utils import BBox3dProjector, BackProjection\n",
    "from visualDet3D.visualDet3D.utils.utils import convertAlpha2Rot, convertRot2Alpha, draw_3D_box, compound_annotation\n",
    "#from visualDet3D.visualDet3D.data.kitti.dataset import *\n",
    "import visualDet3D.visualDet3D.data.kitti.dataset\n",
    "from visualDet3D.visualDet3D.utils.timer import Timer\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "cfg = cfg_from_file('D:/Python_Projects/PhD_project/visualDet3D/config/config.py')\n",
    "is_test_train = True\n",
    "\n",
    "checkpoint_name = 'D:/Python_Projects/PhD_project/visualDet3D/workdirs/Mono3D/checkpoint/GroundAware_pretrained.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "    drawed_image = image.copy()\n",
    "    for box2d in bboxes2d:\n",
    "        cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "    return drawed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualDet3D.data.kitti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     dataset_name \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mval_dataset\n\u001b[1;32m---> 13\u001b[0m dataset \u001b[39m=\u001b[39m DATASET_DICT[dataset_name](\n\u001b[0;32m     14\u001b[0m         cfg, split_to_test\n\u001b[0;32m     15\u001b[0m         )\n\u001b[0;32m     17\u001b[0m \u001b[39mif\u001b[39;00m split_to_test\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     18\u001b[0m     dataset_val \u001b[39m=\u001b[39m DATASET_DICT[cfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mval_dataset](\n\u001b[0;32m     19\u001b[0m             cfg, \u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     20\u001b[0m             )\n",
      "File \u001b[1;32mD:\\Python_Projects\\PhD_project\\visualDet3D\\visualDet3D\\data\\kitti\\dataset\\mono_dataset.py:46\u001b[0m, in \u001b[0;36mKittiMonoDataset.__init__\u001b[1;34m(self, cfg, split)\u001b[0m\n\u001b[0;32m     43\u001b[0m is_train \u001b[39m=\u001b[39m (split \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m imdb_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(preprocessed_path, split, \u001b[39m'\u001b[39m\u001b[39mimdb.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimdb \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(imdb_file_path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39m# list of kittiData\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m     48\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcalib\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mvelodyne\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     }\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m is_train:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visualDet3D.data.kitti'"
     ]
    }
   ],
   "source": [
    "from visualDet3D.visualDet3D.networks.detectors.yolomono3d_detector import GroundAwareYolo3D\n",
    "cfg.batch_size=1\n",
    "split_to_test='validation'\n",
    "\n",
    "is_test_train = split_to_test == 'training'\n",
    "if split_to_test == 'training':\n",
    "    dataset_name = cfg.data.train_dataset\n",
    "elif split_to_test == 'test':\n",
    "    dataset_name = cfg.data.test_dataset\n",
    "else:\n",
    "    dataset_name = cfg.data.val_dataset\n",
    "\n",
    "dataset = DATASET_DICT[dataset_name](\n",
    "        cfg, split_to_test\n",
    "        )\n",
    "\n",
    "if split_to_test=='training':\n",
    "    dataset_val = DATASET_DICT[cfg.data.val_dataset](\n",
    "            cfg, 'validation'\n",
    "            )\n",
    "    dataset.transform = dataset_val.transform\n",
    "    dataset.collate_fn = dataset_val.collate_fn\n",
    "\n",
    "#detector = DETECTOR_DICT[cfg.detector.name](cfg.detector)\n",
    "detector = GroundAwareYolo3D(cfg.detector)\n",
    "detector = detector.cuda()\n",
    "\n",
    "weight_path = os.path.join(cfg.path.checkpoint_path, checkpoint_name)\n",
    "state_dict = torch.load(weight_path, map_location='cuda:{}'.format(cfg.trainer.gpu))\n",
    "new_dict = state_dict.copy()\n",
    "for key in state_dict:\n",
    "    if 'focalLoss' in key:\n",
    "        new_dict.pop(key)\n",
    "detector.load_state_dict(new_dict, strict=False)\n",
    "detector.eval().cuda()\n",
    "\n",
    "# testing pipeline\n",
    "test_func = PIPELINE_DICT[cfg.trainer.test_func]\n",
    "\n",
    "projector = BBox3dProjector().cuda()\n",
    "backprojector = BackProjection().cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
